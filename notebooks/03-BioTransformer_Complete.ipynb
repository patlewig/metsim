{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35c604e1-4408-4e20-b038-d087f9e26c75",
   "metadata": {},
   "source": [
    "### Generation of predictions using BioTransformer\n",
    "- Created by: Louis Groff\n",
    "- PIs: Imran Shah and Grace Patlewicz\n",
    "- Last modified: 4 March 2024\n",
    "- Changes made: Additional note on implementation added from the SI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23ad5dc-2b99-427f-8fb3-3bb9da5e754a",
   "metadata": {},
   "source": [
    "A working copy of BioTransformer is needed. Assuming the input directory contains the BioTransformer Executable Java Archive (JAR) the full Command Line Interface (CLI) input command would be: java -jar BioTransformer3.0_20220615.jar -k pred -q \"ecbased:1;cyp450:2;phaseII:1\" -cm 1 -ismi \"<in.hcd_smiles>\" -ocsv \".\\tmpfiles\\btrans_out_<in.dtxsid>_randomfilename string>.csv\" The randomly suffixed output files generated via the “tempfile” package in Python can either be kept or discarded after data processing is completed. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ba7c8d-ad97-478d-b73f-ea0c0b770609",
   "metadata": {},
   "source": [
    "For the validation datasets, the models used were either “cyp450” for single-step phase I metabolism (Table S2 in the supplemental information), or any mixture of “cyp450”, “ecbased” and “phaseII” that terminated in phase II, whether individual runs or sequential. The CLI command for the highest performing single-step human model (no gut) was:\n",
    "java -jar BioTransformer3.0_20220615.jar -k pred -q \"ecbased:1;cyp450:1;phaseII:1\" -cm 1 -ismi \"<in:smiles>\" -ocsv \".\\tmpfiles\\btrans_out_<in.dtxsid>_randomfile name string>.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aadcbe6-39da-48e5-9c89-df72768905ba",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1. metsim_hcd_out():\n",
    "     Wrapped within the Toolbox WebAPI or BioTransformer calling functions. (Does not require VPN)\n",
    "     input: SMILES string (required), optional are the DTXSID (required for CCD searching), CASRN, and Chemical Names.\n",
    "     action: queries the EPA Hazard Comparison Dashboard (HCD) for JSON output data for a given chemical. If output data exists, relevant chemical/structural identifiers are supplemented to existing metsim outputs.\n",
    "     output: If they exist - DTXSID, Canonical SMILES (hcd_smiles key), CASRN, and InChIKey (via HCD, or RDKit if not in HCD).\n",
    "# 2. metsim_metadata_full():\n",
    "    used to save time between running BioTransformer and gathering metabolite metadata. Since BioTransformer suffers more from the \"combinatorial explosion\" issues of having so many metabolites it produces, which is computationally taxing, we run BioTransformer and save the SMILES and generational tracking from it in our dictionary format as a list of dictionaries, and then later use metsim_metadata_full to fill in the metadata for this list of dictionaries.\n",
    "# 3. btrans_metsim_subprocess():\n",
    "    input: SMILES, List of Models, List of Cycles, Delete Tempfile (True/False)\n",
    "    action: Simulates human metabolism (Default: 2 cycles Phase I/\"cyp450\", 1 cycle Phase II/\"phaseII\") using BioTransformer 3.0 through Java in the command prompt, producing output data in temporary files that can be kept or deleted. Recursively searches through output CSV to process data into a standardized dictionary output.\n",
    "    output: Tuple with dummy index (for parallel processing), Dictionary of precursor and successor SMILES, CASRN, DTXSID, InChIKey as supplemented by HCD (or RDKit for InChIKey), and filename (if del_tmp = False)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5aa55504-4fa5-49de-9fc2-86c8816d657f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import urllib.request, urllib.parse, json\n",
    "import time\n",
    "import tempfile\n",
    "from rdkit import Chem\n",
    "import datetime\n",
    "#import multiprocess as mp\n",
    "from itertools import compress\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b67a417-b8e0-4ea8-a54f-7f9715fb14a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function 1: HCD Queries\n",
    "def metsim_hcd_out(smiles = None, \n",
    "                   casrn = None,\n",
    "                   dtxsid = None,\n",
    "                   inchikey = None,\n",
    "                   chem_name = None,\n",
    "                   likely = None):\n",
    "    \"\"\"\n",
    "    Query function for the Cheminformatics Modules Standardizer API, formerly wrapped within the Hazard Comparison Dashboard (HCD) API. \n",
    "    Used to convert an input SMILES string into QSAR-Ready SMILES. Returns InChIKey structural identifier as well,\n",
    "    along with any other chemical identifer metadata if available, and not already given as inputs (e.g., CASRN, DTXSID, Chemical Name).\n",
    "    \n",
    "    If SMILES is not known, but DTXSID is known, can instead query on DTXSID to obtain Daylight SMILES from the Comptox Chemicals Dashboard API (CCD API),\n",
    "    and subsequently query the Standardizer API using the SMILES obtained from the CCD API.\n",
    "    \n",
    "    Required Inputs:\n",
    "    smiles: Daylight SMILES string\n",
    "    or\n",
    "    dtxsid: DSSTox Substance Identifier\n",
    "    \n",
    "    Optional Inputs:\n",
    "    chem_name: Chemical name, whether trade name or IUPAC\n",
    "    casrn: Chemical Abstracts Services Registry Number\n",
    "    inchikey: International Chemical Identifier Key (InChIKey)\n",
    "    likely: If MetSim predictions are obtained from the Chemical Transformation Simulator, can optionally keep the transformation \"likelihood\" parameter\n",
    "    \n",
    "    Returns:\n",
    "    out_dict: Output dictionary containing all available output data for the given chemical, using the input parameter names as dictionary keys.\n",
    "    Includes \"hcd_smiles\" as output dictionary key containing QSAR-Ready version of the input SMILES.\n",
    "    \n",
    "    Examples:\n",
    "    \n",
    "    SMILES given as sole input:\n",
    "    input:    \n",
    "    test_dict = metsim_hcd_out(smiles = \"OCCOCCO\")\n",
    "    \n",
    "    output:\n",
    "    Attempting query of Cheminformatics Modules Standardizer with SMILES: OCCOCCO...\n",
    "    Query succeeded.\n",
    "    test_dict\n",
    "    {'smiles': 'OCCOCCO',\n",
    "     'casrn': '111-46-6',\n",
    "     'hcd_smiles': 'OCCOCCO',\n",
    "     'inchikey': 'MTHSVFCYNBDYFN-UHFFFAOYNA-N',\n",
    "     'dtxsid': 'DTXSID8020462',\n",
    "     'chem_name': 'Diethylene glycol',\n",
    "     'likelihood': None}\n",
    "    \n",
    "    DTXSID given as sole input:\n",
    "    \n",
    "    input:    \n",
    "    test_dict = metsim_hcd_out(dtxsid = \"DTXSID4020402\")\n",
    "    \n",
    "    output:\n",
    "    Attempting query of Comptox Chemicals Dashboard with DTXSID: DTXSID4020402...\n",
    "    Query succeeded.\n",
    "    No SMILES given. Using CCD output SMILES.\n",
    "    Attempting query of Cheminformatics Modules Standardizer with SMILES: CC1=C(N)C=C(N)C=C1...\n",
    "    Query succeeded.\n",
    "    test_dict\n",
    "    {'smiles': 'CC1=C(N)C=C(N)C=C1',\n",
    "     'casrn': '95-80-7',\n",
    "     'hcd_smiles': 'CC1C=CC(N)=CC=1N',\n",
    "     'inchikey': 'VOZKAJLKRJDJLL-UHFFFAOYNA-N',\n",
    "     'dtxsid': 'DTXSID4020402',\n",
    "     'chem_name': '2,4-Diaminotoluene',\n",
    "     'likelihood': None}\n",
    "     \n",
    "     Empty inputs:\n",
    "     input:\n",
    "     test_dict = metsim_hcd_out(smiles = None, dtxsid = None)\n",
    "     \n",
    "     output:\n",
    "     test_dict\n",
    "     {'smiles': None,\n",
    "     'casrn': None,\n",
    "     'hcd_smiles': None,\n",
    "     'inchikey': None,\n",
    "     'dtxsid': None,\n",
    "     'chem_name': None,\n",
    "     'likelihood': None}\n",
    "    \"\"\"\n",
    "    \n",
    "    ccd_out = []\n",
    "    if dtxsid != None and smiles == None:\n",
    "        #get metadata from Comptox Chemicals Dashboard for a given DTXSID (No structure searching atm).\n",
    "        ccd_url = 'https://comptox.epa.gov/dashboard-api/ccdapp2/chemical-detail/search/by-dsstoxsid?id='+dtxsid\n",
    "        ccd_success = 0\n",
    "        try_count = 0\n",
    "        while ccd_success == 0 and try_count < 3:\n",
    "            try:\n",
    "                print('Attempting query of Comptox Chemicals Dashboard with DTXSID: '+dtxsid+'...')\n",
    "                ccd_out = json.loads(urllib.request.urlopen(ccd_url).read().decode())\n",
    "                \n",
    "                ccd_success = 1\n",
    "                try_count+=1\n",
    "            except:\n",
    "                #Given that this occasionally fails randomly due to timeout errors, \n",
    "                #but then works again later, try again after a 1 second pause.\n",
    "                #Should work on second attempt.\n",
    "                print('URL Error Occurred, reattempting CCD query in 0.5 seconds.')\n",
    "                time.sleep(0.5)\n",
    "                try_count+=1\n",
    "            print('Query succeeded.')\n",
    "    if smiles != None or len(ccd_out) > 0:\n",
    "        if smiles != None:\n",
    "            smiles_url = urllib.parse.quote_plus(smiles) #URL encode SMILES string.\n",
    "        elif len(ccd_out) > 0 and ccd_out['smiles'] != None:\n",
    "            print('No SMILES given. Using CCD output SMILES.')\n",
    "            smiles = ccd_out['smiles']\n",
    "            smiles_url = urllib.parse.quote_plus(smiles) #URL enconde CCD smiles string.\n",
    "        else:\n",
    "            print('No SMILES given, and no SMILES available from CCD output.')\n",
    "            smiles_url = None\n",
    "        base_url = \"https://hcd.rtpnc.epa.gov/api/stdizer?workflow=qsar-ready&smiles=\" #Production environment (current, no VPN needed)\n",
    "        # base_url = \"https://hazard-dev.sciencedataexperts.com/api/stdizer?workflow=qsar-ready&smiles=\" #Dev environment (no VPN needed)\n",
    "        # base_url = \"https://hazard.sciencedataexperts.com/api/stdizer?workflow=qsar-ready&smiles=\" #Production environment (VPN needed)\n",
    "        if smiles_url != None:\n",
    "            hcd_url = base_url+smiles_url\n",
    "            hcd_success = 0\n",
    "            try_count = 0\n",
    "            hcd_out = []\n",
    "            while hcd_success == 0 and try_count < 3:\n",
    "                try:\n",
    "                    print('Attempting query of Cheminformatics Modules Standardizer with SMILES: '+smiles+'...')\n",
    "                    time.sleep(0.5)\n",
    "                    hcd_out = json.loads(urllib.request.urlopen(hcd_url).read().decode())\n",
    "                    print('Query succeeded.')\n",
    "                    hcd_success = 1\n",
    "                    try_count+=1\n",
    "                except:\n",
    "                    #Given that this occasionally fails randomly due to timeout errors, \n",
    "                    #but then works again later, try again after a 1 second pause.\n",
    "                    #Should work on second attempt.\n",
    "                    print('URL Error Occurred, reattempting Cheminformatics Modules query in 0.5 seconds.')\n",
    "                    time.sleep(0.5)\n",
    "                    try_count+=1\n",
    "            if len(hcd_out) > 0:\n",
    "                out_dict = {'smiles': smiles, \n",
    "                            'casrn': casrn,\n",
    "                            'hcd_smiles': hcd_out[0]['smiles'],\n",
    "                            'inchikey': hcd_out[0]['inchiKey'],\n",
    "                            'dtxsid': dtxsid,\n",
    "                            'chem_name': chem_name,\n",
    "                            'likelihood': likely}\n",
    "                if out_dict['dtxsid'] == None:\n",
    "                    if 'DTXSID' in hcd_out[0]['id']:\n",
    "                        out_dict['dtxsid'] = hcd_out[0]['id']\n",
    "                    elif len(ccd_out) > 0 and ccd_out['dsstoxSubstanceId'] != None:\n",
    "                        out_dict['dtxsid'] = ccd_out['dsstoxSubstanceId']\n",
    "                if out_dict['casrn'] == None:\n",
    "                    if 'casrn' in hcd_out[0].keys():\n",
    "                        out_dict['casrn'] = hcd_out[0]['casrn']\n",
    "                    elif len(ccd_out) > 0 and ccd_out['casrn'] != None:\n",
    "                        out_dict['casrn'] = ccd_out['casrn']\n",
    "                if out_dict['chem_name'] == None:\n",
    "                    if len(ccd_out) > 0 and ccd_out['preferredName'] != None:\n",
    "                        out_dict['chem_name'] = ccd_out['preferredName']\n",
    "                    elif 'name' in hcd_out[0].keys():\n",
    "                        out_dict['chem_name'] = hcd_out[0]['name']\n",
    "                if out_dict['inchikey'] == None and len(ccd_out) > 0:\n",
    "                    if ccd_out['inchiKey'] != None:\n",
    "                        out_dict['inchikey'] = ccd_out['inchiKey'] \n",
    "            else:\n",
    "                out_dict = {'smiles': smiles,\n",
    "                            'casrn': casrn,\n",
    "                            'hcd_smiles': None,\n",
    "                            'inchikey': None,\n",
    "                            'dtxsid': dtxsid,\n",
    "                            'chem_name': chem_name,\n",
    "                            'likelihood': likely\n",
    "                           }\n",
    "                #HCD Returns empty list. Try to supplement with metadata from RDKit.\n",
    "                try:\n",
    "                    smiles_mol = Chem.MolFromSmiles(smiles)\n",
    "                    out_dict['inchikey'] = Chem.inchi.MolToInchiKey(smiles_mol)\n",
    "                except:\n",
    "                    #Rarely, BioTransformer makes a bad SMILES string for a metabolite, and RDKit can't convert it to an InChIKey. Store None\n",
    "                    print('RDKit failed to generate an inchikey for SMILES: '+smiles)\n",
    "                    out_dict['inchikey'] = None\n",
    "        else:\n",
    "            out_dict = {'smiles': smiles,\n",
    "                        'casrn': casrn,\n",
    "                        'hcd_smiles': None,\n",
    "                        'inchikey': None,\n",
    "                        'dtxsid': dtxsid,\n",
    "                        'chem_name': chem_name,\n",
    "                        'likelihood': likely\n",
    "                       }\n",
    "    else:\n",
    "        out_dict = {'smiles': smiles,\n",
    "                    'casrn': casrn,\n",
    "                    'hcd_smiles': None,\n",
    "                    'inchikey': None,\n",
    "                    'dtxsid': dtxsid,\n",
    "                    'chem_name': chem_name,\n",
    "                    'likelihood': likely\n",
    "                   }\n",
    "    return out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a466b7dc-5836-4014-979a-6414ba1e8594",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def metsim_metadata_full(metsim_out = [], fnam = None, metsim_cache = None):\n",
    "    \n",
    "    if len(metsim_out) > 0:\n",
    "        if metsim_cache != None:\n",
    "            #Supplement metadata via serial HCD query through individual input chemicals, precursors, successors/metabolites for a full metsim dataset\n",
    "            for i in range(len(metsim_out)): # i = number of input chemicals\n",
    "                if metsim_out[i]['input']['inchikey'] != None:\n",
    "                        continue\n",
    "                if metsim_out[i]['input']['smiles'] not in [cache_item['smiles'] for cache_item in metsim_cache]:\n",
    "                    metsim_out[i]['input'] = metsim_hcd_out(smiles = metsim_out[i]['input']['smiles'],\n",
    "                                                            casrn = metsim_out[i]['input']['casrn'],\n",
    "                                                            dtxsid = metsim_out[i]['input']['dtxsid'],\n",
    "                                                            chem_name = metsim_out[i]['input']['chem_name'])\n",
    "                    metsim_cache.append(metsim_out[i]['input'])\n",
    "                    print('Input query added to metadata cache...')\n",
    "                else:\n",
    "                    print('Input SMILES found in cached results. Inserting into dictionary...')\n",
    "                    metsim_out[i]['input'] = metsim_cache[[idx for idx in range(len(metsim_cache)) if metsim_cache[idx]['smiles'] == metsim_out[i]['input']['smiles']][0]]\n",
    "                for j in range(len(metsim_out[i]['output'])): # j = number of unique precursors\n",
    "                    if 'likelihood' in list(metsim_out[i]['output'][j]['precursor'].keys()):\n",
    "                        if metsim_out[i]['output'][j]['precursor']['smiles'] not in [cache_item['smiles'] for cache_item in metsim_cache]:\n",
    "                            metsim_out[i]['output'][j]['precursor'] = metsim_hcd_out(smiles = metsim_out[i]['output'][j]['precursor']['smiles'],\n",
    "                                                                                     casrn = metsim_out[i]['output'][j]['precursor']['casrn'],\n",
    "                                                                                     dtxsid = metsim_out[i]['output'][j]['precursor']['dtxsid'],\n",
    "                                                                                     chem_name = metsim_out[i]['output'][j]['precursor']['chem_name'],\n",
    "                                                                                     likely = metsim_out[i]['output'][j]['precursor']['likelihood'])\n",
    "                            metsim_cache.append(metsim_out[i]['output'][j]['precursor'])\n",
    "                            print('Precursor query added to metadata cache...')\n",
    "                        else:\n",
    "                            print('Precursor SMILES found in cached results. Inserting into dictionary...')\n",
    "                            metsim_out[i]['output'][j]['precursor'] = metsim_cache[[idx for idx in range(len(metsim_cache)) if metsim_cache[idx]['smiles'] == metsim_out[i]['output'][j]['precursor']['smiles']][0]]\n",
    "                    else:\n",
    "                        if metsim_out[i]['output'][j]['precursor']['smiles'] not in [cache_item['smiles'] for cache_item in metsim_cache]:\n",
    "                            metsim_out[i]['output'][j]['precursor'] = metsim_hcd_out(smiles = metsim_out[i]['output'][j]['precursor']['smiles'],\n",
    "                                                                                     casrn = metsim_out[i]['output'][j]['precursor']['casrn'],\n",
    "                                                                                     dtxsid = metsim_out[i]['output'][j]['precursor']['dtxsid'],\n",
    "                                                                                     chem_name = metsim_out[i]['output'][j]['precursor']['chem_name'])\n",
    "                            metsim_cache.append(metsim_out[i]['output'][j]['precursor'])\n",
    "                            print('Precursor query added to metadata cache...')\n",
    "                        else:\n",
    "                            print('Precursor SMILES found in cached results. Inserting into dictionary...')\n",
    "                            metsim_out[i]['output'][j]['precursor'] = metsim_cache[[idx for idx in range(len(metsim_cache)) if metsim_cache[idx]['smiles'] == metsim_out[i]['output'][j]['precursor']['smiles']][0]]\n",
    "                    for k in range(len(metsim_out[i]['output'][j]['successors'])): # k = number of metabolites per precursor\n",
    "                        if 'likelihood' in list(metsim_out[i]['output'][j]['successors'][k]['metabolite'].keys()):\n",
    "                            if metsim_out[i]['output'][j]['successors'][k]['metabolite']['smiles'] not in [cache_item['smiles'] for cache_item in metsim_cache]:\n",
    "                                metsim_out[i]['output'][j]['successors'][k]['metabolite'] = metsim_hcd_out(smiles = metsim_out[i]['output'][j]['successors'][k]['metabolite']['smiles'],\n",
    "                                                                                                           casrn = metsim_out[i]['output'][j]['successors'][k]['metabolite']['casrn'],\n",
    "                                                                                                           dtxsid = metsim_out[i]['output'][j]['successors'][k]['metabolite']['dtxsid'],\n",
    "                                                                                                           chem_name = metsim_out[i]['output'][j]['successors'][k]['metabolite']['chem_name'],\n",
    "                                                                                                           likely = metsim_out[i]['output'][j]['successors'][k]['metabolite']['likelihood'])\n",
    "                                metsim_cache.append(metsim_out[i]['output'][j]['successors'][k]['metabolite'])\n",
    "                                print('Successor metabolite query added to metadata cache...')\n",
    "                            else:\n",
    "                                print('Successor metabolite SMILES found in cached results. Inserting into dictionary...')\n",
    "                                metsim_out[i]['output'][j]['successors'][k]['metabolite'] = metsim_cache[[idx for idx in range(len(metsim_cache)) if metsim_cache[idx]['smiles'] == metsim_out[i]['output'][j]['successors'][k]['metabolite']['smiles']][0]] \n",
    "                        else:\n",
    "                            if metsim_out[i]['output'][j]['successors'][k]['metabolite']['smiles'] not in [cache_item['smiles'] for cache_item in metsim_cache]:\n",
    "                                metsim_out[i]['output'][j]['successors'][k]['metabolite'] = metsim_hcd_out(smiles = metsim_out[i]['output'][j]['successors'][k]['metabolite']['smiles'],\n",
    "                                                                                                           casrn = metsim_out[i]['output'][j]['successors'][k]['metabolite']['casrn'],\n",
    "                                                                                                           dtxsid = metsim_out[i]['output'][j]['successors'][k]['metabolite']['dtxsid'],\n",
    "                                                                                                           chem_name = metsim_out[i]['output'][j]['successors'][k]['metabolite']['chem_name'])\n",
    "                                metsim_cache.append(metsim_out[i]['output'][j]['successors'][k]['metabolite'])\n",
    "                                print('Successor metabolite query added to metadata cache...')\n",
    "                            else:\n",
    "                                print('Successor metabolite SMILES found in cached results. Inserting into dictionary...')\n",
    "                                metsim_out[i]['output'][j]['successors'][k]['metabolite'] = metsim_cache[[idx for idx in range(len(metsim_cache)) if metsim_cache[idx]['smiles'] == metsim_out[i]['output'][j]['successors'][k]['metabolite']['smiles']][0]] \n",
    "                        print('input: '+str(i+1)+'/'+str(len(metsim_out))+' precursor: '+str(j+1)+'/'+str(len(metsim_out[i]['output']))+' metabolite: '+str(k+1)+'/'+str(len(metsim_out[i]['output'][j]['successors'])))\n",
    "                if fnam != None:\n",
    "                    json.dump(metsim_out, open(fnam,'w'))\n",
    "        else:\n",
    "            return metsim_metadata_full(metsim_out = metsim_out, fnam = fnam, metsim_cache = [])\n",
    "    else:\n",
    "        raise('Please supply a metsim dataset (list of dictionaries)')\n",
    "    # print(metsim_out)\n",
    "    return metsim_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6e1bdf3-244c-4ad3-9af3-cff10b02c6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for generational tracking of output:\n",
    "def recursive_gen_list(input_df = None,\n",
    "                       parent_list = [],\n",
    "                       successor_list = None,\n",
    "                       out_list = [],\n",
    "                       gen = 1):\n",
    "    if type(input_df) == 'NoneType':\n",
    "        raise('Please include BioTransformer output csv dataframe as input_df.')\n",
    "    successor_dict = {}\n",
    "    for i in parent_list.index:\n",
    "        if pd.isna(parent_list[i]):\n",
    "            successor_df = input_df.loc[pd.isna(input_df['Precursor ID']),:]\n",
    "            successor_list = successor_df['Metabolite ID']\n",
    "            print(str(len(successor_list))+' Successors found for parent chemical')\n",
    "        else:\n",
    "            successor_df = input_df.loc[input_df['Precursor ID'] == parent_list[i],:]\n",
    "            successor_list = successor_df['Metabolite ID']\n",
    "        if len(successor_list) > 0:\n",
    "\n",
    "            successor_dict = {'precursor': {'smiles': successor_df['Precursor SMILES'].unique()[0],\n",
    "                                        'inchikey': None,\n",
    "                                        'casrn': None,\n",
    "                                        'hcd_smiles': None,\n",
    "                                        'dtxsid': None,\n",
    "                                        'chem_name': None\n",
    "                                       },\n",
    "                          'successors': [{'enzyme': successor_df.loc[j,'Enzyme(s)'].split('\\n'),\n",
    "                                          'mechanism': successor_df.loc[j,'Reaction'],\n",
    "                                          'generation': gen,\n",
    "                                          'metabolite': {'smiles': successor_df.loc[j,'SMILES'],\n",
    "                                                         'inchikey': None,\n",
    "                                                         'casrn': None,\n",
    "                                                         'hcd_smiles': None,\n",
    "                                                         'dtxsid': None,\n",
    "                                                         'chem_name': None\n",
    "                                                        }\n",
    "                                       } for j in successor_df.index]\n",
    "                             }\n",
    "            if pd.notna(parent_list[i]):\n",
    "                print(str(len(successor_df))+' successors found for gen '+str(gen)+' precursor '+parent_list[i])\n",
    "            if successor_dict['precursor']['smiles'] in [out_list[j]['precursor']['smiles'] for j in range(len(out_list))]:\n",
    "                print('Precursor-successor relationship already recorded, skipping to next precursor.')\n",
    "            else:\n",
    "                out_list = out_list+[successor_dict]\n",
    "                print('dict added to out_list for index '+str(i))\n",
    "                #check for more generations:\n",
    "                for k in successor_list.index:\n",
    "                    print('starting recursion on successor index '+str(k))\n",
    "                    out_list = recursive_gen_list(input_df = input_df,\n",
    "                                                  parent_list = pd.Series(successor_list[k]),\n",
    "                                                  successor_list = [],\n",
    "                                                  out_list = out_list,\n",
    "                                                  gen = gen+1)\n",
    "                    print('recursion complete for successor index '+str(k))\n",
    "            return out_list\n",
    "        else:\n",
    "            print('No successors for gen '+str(gen)+' precursor '+parent_list[i]+', moving to next gen 1 precursor.')\n",
    "            gen = 1\n",
    "            return out_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1716ff2-2505-4c37-8345-ddf0cc931c33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function 3: BioTransformer 3.0 Human Phase I + Phase II Metsim.\n",
    "def btrans_metsim_subprocess(models = ['cyp450','phaseII'],\n",
    "                             cyp_mode = 1,\n",
    "                             cycles = [2,1],\n",
    "                             smiles = None,\n",
    "                             casrn = None,\n",
    "                             del_tmp = False,\n",
    "                             dtxsid = None,\n",
    "                             chem_name = None,\n",
    "                             idx = None,\n",
    "                             multi_proc = False):\n",
    "    \n",
    "    import pandas as pd\n",
    "    import datetime\n",
    "    import os\n",
    "    import subprocess\n",
    "    import tempfile\n",
    "    \n",
    "# Need to determine how to implement recursion with multiprocessing...\n",
    "    \n",
    "    #set up initial dictionary outputs:\n",
    "    btrans_dict = {'datetime': str(datetime.datetime.now().strftime('%Y-%m-%d_%Hh%Mm%Ss')),\n",
    "                   'software': 'BioTransformer',\n",
    "                   'version': 3.0,\n",
    "                   'params':{'depth': sum([cycles[i] if ('allHuman' != models[i]) and ('superbio' != models[i]) else 4 for i in range(len(cycles))]),\n",
    "                             'organism': 'Human',\n",
    "                             'site_of_metabolism': False,\n",
    "                             'model': [str(cycles[i])+'x '+models[i] for i in range(len(models))]\n",
    "                            }\n",
    "                  }\n",
    "    btrans_dict['input'] = {'smiles': smiles,\n",
    "                            'inchikey': None,\n",
    "                            'casrn': casrn,\n",
    "                            'hcd_smiles': None,\n",
    "                            'dtxsid': dtxsid,\n",
    "                            'chem_name': chem_name\n",
    "                           } \n",
    "    \n",
    "    #change directory to BioTransformer directory\n",
    "    btrans_dir = 'C:/Users/lgroff/OneDrive - Environmental Protection Agency (EPA)/Profile/Documents/Data/GenRA/BioTransformer3.0'\n",
    "    # btrans_dir = 'C:/Users/lgroff/OneDrive - Environmental Protection Agency (EPA)/Profile/Documents/Data/GenRA/BioTransformer1.1.5'\n",
    "    if os.curdir != btrans_dir:\n",
    "        os.chdir(btrans_dir)\n",
    "       \n",
    "    if pd.notna(smiles): #check that we have a SMILES string input\n",
    "        #Begin constructing BioTransformer input command string:\n",
    "        btrans_cmd = 'java -jar BioTransformer3.0_20220615.jar -k pred ' #current version\n",
    "        # btrans_cmd = 'java -jar BioTransformer-1.1.5.jar -k pred ' #2019 paper version\n",
    "        # btrans_cmd = 'java -jar BioTransformer-1-0-6.jar -k pred ' #original version (Only uses single models!)\n",
    "        #incorporate model parameters into command string:\n",
    "        if len(models) == 1:\n",
    "            btrans_model = '-b \"'+models[0]+'\" '\n",
    "            if cycles[0] > 1:\n",
    "                btrans_model = btrans_model+'-s '+str(cycles[0])\n",
    "        else:\n",
    "            btrans_model = '-q \"'\n",
    "            for i in range(len(models)):\n",
    "                if i < len(models)-1:\n",
    "                    btrans_model = btrans_model+models[i]+':'+str(cycles[i])+';'\n",
    "                else:\n",
    "                    btrans_model = btrans_model+models[i]+':'+str(cycles[i])+'\" '\n",
    "        btrans_cmd = btrans_cmd+btrans_model+' -cm '+str(cyp_mode)+' ' #specify cyp_mode with later versions of BioTransformer\n",
    "        # btrans_cmd = btrans_cmd+btrans_model+' ' #no cyp_mode in input command for original 2019 relase of BioTransformer\n",
    "        \n",
    "        #create temporary file to store BioTransformer output:\n",
    "        print('Generating output tempfile for index '+str(idx)+', DTXSID: '+str(dtxsid)+'...')\n",
    "        fnum, fnam = tempfile.mkstemp(dir = './tmpfiles',\n",
    "                                      prefix = 'btrans_out_'+dtxsid+'_',\n",
    "                                      suffix = '.csv')\n",
    "        \n",
    "        #Finish constructing input command using the tempfile name:\n",
    "        fnam_split = fnam.split('\\\\')\n",
    "        btrans_fnam = '.\\\\'+fnam_split[-2]+'\\\\'+fnam_split[-1]\n",
    "        #insert input smiles string and output csv tempfile name:\n",
    "        btrans_cmd = btrans_cmd + '-ismi \"'+smiles+'\" -ocsv \"'+btrans_fnam+'\"' #use Daylight SMILES input\n",
    "        # btrans_cmd = btrans_cmd + '-isdf \"'+smiles+'\" -ocsv \"'+btrans_fnam+'\"'\n",
    "        print(btrans_cmd)\n",
    "        #Run BioTransformer with subprocess and the appropriate input command string:\n",
    "        print('beginning metsim for index #'+str(idx)+'...')\n",
    "        btrans_out = subprocess.run(btrans_cmd,\n",
    "                                    shell=True,\n",
    "                                    stdout=subprocess.PIPE) \n",
    "        \n",
    "        #Preallocate data frame and read tempfile output if BioTransformer ran successfully:\n",
    "        btrans_out_df = pd.DataFrame()\n",
    "        if btrans_out.stderr == None:\n",
    "            try:\n",
    "                btrans_out_df = pd.read_csv(fnam)\n",
    "            except:\n",
    "                pass\n",
    "        else:\n",
    "            print('error, check stdout')\n",
    "            print(btrans_out.stdout.decode())\n",
    "            \n",
    "        btrans_dict['output'] = []\n",
    "        if multi_proc == False:\n",
    "            #Process metabolism data (if it exists for the given smiles):\n",
    "            if os.path.getsize(fnam) > 0:\n",
    "                input_df = pd.read_csv(fnam)\n",
    "                parent_list = input_df['Precursor ID']\n",
    "                parent_list = parent_list.drop_duplicates()\n",
    "                btrans_dict['output'] = recursive_gen_list(input_df = input_df,\n",
    "                                                           parent_list = parent_list,\n",
    "                                                           successor_list = [],\n",
    "                                                           out_list = [],\n",
    "                                                           gen = 1)\n",
    "            else: #Valid SMILES given, no metabolites produced:\n",
    "                print('No metabolites produced for index #'+str(i))\n",
    "                btrans_dict['output'] = [{'precursor': btrans_dict['input'],\n",
    "                                          'successors': [{'enzyme': [],\n",
    "                                                          'mechanism': None,\n",
    "                                                          'generation': None,\n",
    "                                                          'metabolite': {'smiles': None,\n",
    "                                                                         'inchikey': None,\n",
    "                                                                         'casrn': None,\n",
    "                                                                         'hcd_smiles': None,\n",
    "                                                                         'dtxsid': None,\n",
    "                                                                         'chem_name': None\n",
    "                                                                        }\n",
    "                                                        }]\n",
    "                                        }]\n",
    "        else:\n",
    "            #Need to determine how to multiprocess recursion, until then, store input parameters and output structure.\n",
    "            btrans_dict['output'] = [{'precursor': btrans_dict['input'],\n",
    "                                      'successors': [{'enzyme': [],\n",
    "                                                      'mechanism': None,\n",
    "                                                      'generation': None,\n",
    "                                                      'metabolite': {'smiles': None,\n",
    "                                                                     'inchikey': None,\n",
    "                                                                     'casrn': None,\n",
    "                                                                     'hcd_smiles': None,\n",
    "                                                                     'dtxsid': None,\n",
    "                                                                     'chem_name': None\n",
    "                                                                    }\n",
    "                                                    }]\n",
    "                                    }]\n",
    "        #close temporary output file. Will delete if del_tempfile function input is set to True.\n",
    "        os.close(fnum)\n",
    "        if del_tmp == True:\n",
    "            os.remove(fnam)\n",
    "    else:\n",
    "        print('No SMILES string provided for index #'+str(idx)+\".\")\n",
    "        #This list returns if no metabolites are formed/BioTransformer fails.\n",
    "        btrans_dict['output'] = [{'precursor': {'smiles': None,\n",
    "                                                'inchikey': None,\n",
    "                                                'casrn': None,\n",
    "                                                'hcd_smiles': None,\n",
    "                                                'dtxsid': None,\n",
    "                                                'chem_name': None\n",
    "                                               },\n",
    "                                  'successors': [{'enzyme': [],\n",
    "                                                  'mechanism': None,\n",
    "                                                  'generation': None,\n",
    "                                                  'metabolite': {'smiles': None,\n",
    "                                                                 'inchikey': None,\n",
    "                                                                 'casrn': None,\n",
    "                                                                 'hcd_smiles': None,\n",
    "                                                                 'dtxsid': None,\n",
    "                                                                 'chem_name': None\n",
    "                                                                }\n",
    "                                                }]\n",
    "                                }]\n",
    "        btrans_dict['input'] = {'smiles': None,\n",
    "                                'inchikey': None,\n",
    "                                'casrn': None,\n",
    "                                'hcd_smiles': None,\n",
    "                                'dtxsid': None,\n",
    "                                'chem_name': None\n",
    "                               }\n",
    "    print('MetSim complete for index '+str(idx)+'.')\n",
    "    if del_tmp == False:\n",
    "        #until figuring out how to implement recursive metabolite search with multiprocessing, return filename for separate analysis function.\n",
    "        return (idx, btrans_dict, fnam)\n",
    "    else:\n",
    "        return (idx, btrans_dict, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f802e5-9c03-4f82-87c2-b5657049bc96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Load in existing dictionary instead of rerunning.\n",
    "#github URL for RAW readout of SMPDB_59Parents.json (update token in URL as necessary)\n",
    "smpdb_obs_pathways = json.loads(open('smpdb_jcim_valid_aggregate_112parents.json','r'))\n",
    "\n",
    "out_list = []\n",
    "pool = mp.Pool(mp.cpu_count()) #define number of available CPU cores for multiprocessing.\n",
    "\n",
    "out_list = pool.starmap_async(btrans_metsim_subprocess,\n",
    "                              #arguments (must be listed in the same order as given in the function definition):\n",
    "                              [(['ecbased','cyp450','phaseII'], #models\n",
    "                                 1, #cyp_mode\n",
    "                                 [1,2,1], #cycles\n",
    "                                 smpdb_obs_pathways[idx]['input']['hcd_smiles'], #smiles\n",
    "                                 smpdb_obs_pathways[idx]['input']['casrn'], #casrn\n",
    "                                 False, #del_tmp\n",
    "                                 smpdb_obs_pathways[idx]['input']['dtxsid'], #dtxsid\n",
    "                                 smpdb_obs_pathways[idx]['input']['chem_name'], #chem_name\n",
    "                                 idx, #index\n",
    "                                 True #multi_proc\n",
    "                               )\n",
    "                               for idx in range(len(smpdb_obs_pathways[0:4]))]).get() #show for first four chemicals in SMPDB dataset as a test\n",
    "\n",
    "pool.close() #close the processing pool to release resources.\n",
    "\n",
    "# Post-processing of multiprocessed BioTransformer Data\n",
    "for i in range(len(out_list)):\n",
    "    if os.path.getsize(out_list[i][2]) > 0:\n",
    "        input_df = pd.read_csv(out_list[i][2])\n",
    "        parent_list = input_df['Precursor ID']\n",
    "        parent_list = parent_list.drop_duplicates()\n",
    "        out_list[i][1]['output'] = recursive_gen_list(input_df = input_df,\n",
    "                                                      parent_list = parent_list,\n",
    "                                                      successor_list = [],\n",
    "                                                      out_list = [],\n",
    "                                                      gen = 1)\n",
    "    else: #Valid SMILES given, no metabolites produced:\n",
    "            print('No metabolites produced for index #'+str(i))\n",
    "            out_list[i][1]['output'] = [{'precursor': out_list[i][1]['input'],\n",
    "                                         'successors': [{'enzyme': [],\n",
    "                                                         'mechanism': None,\n",
    "                                                         'generation': None,\n",
    "                                                         'metabolite': {'smiles': None,\n",
    "                                                                        'inchikey': None,\n",
    "                                                                        'casrn': None,\n",
    "                                                                        'hcd_smiles': None,\n",
    "                                                                        'dtxsid': None,\n",
    "                                                                        'chem_name': None\n",
    "                                                                       }\n",
    "                                                       }]\n",
    "                                       }]\n",
    "preds_complete = [out_list[i][1] for i in range(len(out_list))]\n",
    "json.dump(preds_complete,open('metsim_biotransformer_1xecbased_2xcyp450_1xphase2_smpdb_test.json','w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "67acd47a-6be6-44a0-826f-58ac5acafd14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds_complete_all_metadata = metsim_metadata_full(preds_complete_all_metadata,fnam = 'metsim_biotransformer_1xecbased_2xcyp450_1xphase2_smpdb_test.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
